# VISION : Image captioning model for visually impaired 

• Developed a deep recurrent architecture (LSTM) to produce easily understandable image captions for visually impaired.

• Employed benchmark MS COCO 2017 dataset in an LSTM and CNN network comprising 80k training and 30k testing images.

• Achieved 73% accuracy in real environment scenario of blind people and compiled results in a research paper.
